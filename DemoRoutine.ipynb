{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maithili/.conda/envs/pyml/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from GraphTranslatorModule import GraphTranslatorModule\n",
    "from encoders import TimeEncodingOptions\n",
    "from graph_visualizations import visualize_conditional_datapoint\n",
    "from reader import RoutinesDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph():\n",
    "    def __init__(self, root='kitchen'):\n",
    "        self.root = root\n",
    "        self.parents = {}\n",
    "        self.category = {root:'Rooms'}\n",
    "    \n",
    "    def add(self, node, parent, category='placable_object'):\n",
    "        assert parent in self.parents.keys() or parent == self.root\n",
    "        self.parents[node] = parent\n",
    "        self.category[node] = category\n",
    "\n",
    "    def draw(self):\n",
    "        G = nx.DiGraph()\n",
    "        G.add_nodes_from(list(self.parents.keys()))\n",
    "        G.add_edges_from([(n, self.parents[n]) for n in self.parents])\n",
    "        still_remaining = deepcopy(list(self.parents.keys()))\n",
    "        nodelists = [[self.root]]\n",
    "        while(len(still_remaining)):\n",
    "            new_layer = []\n",
    "            remaining_nodes = still_remaining\n",
    "            still_remaining = []\n",
    "            for n in remaining_nodes:\n",
    "                if self.parents[n] in nodelists[-1]:\n",
    "                    # print(n)\n",
    "                    new_layer.append(n)\n",
    "                else:\n",
    "                    still_remaining.append(n)\n",
    "            nodelists.append(new_layer)\n",
    "            # print(new_layer)\n",
    "        nx.draw_networkx(G)\n",
    "    \n",
    "    def move(self, object, location):\n",
    "        assert location in self.parents.keys() or location == self.root\n",
    "        self.parents[object] = location\n",
    "    \n",
    "    def to_dict(self):\n",
    "        id_map = {self.root:0}\n",
    "        id_map .update({n:i+1 for i,n in enumerate(self.parents.keys())})\n",
    "        graph_dict = {}\n",
    "        graph_dict['nodes'] = [{'id':i, 'class_name':n, 'category':self.category[n]} for n,i in id_map.items()]\n",
    "        graph_dict['edges'] = [{'from_id':id_map[n], 'to_id':id_map[p], 'relation_type':'INSIDE'} for n,p in self.parents.items()]\n",
    "        return graph_dict\n",
    "\n",
    "    def dump(self, filename):\n",
    "        graph_dict = self.to_dict()\n",
    "        with open (filename, 'w') as f:\n",
    "            json.dump(graph_dict, f, indent=4)\n",
    "\n",
    "    def num_nodes(self):\n",
    "        return len(self.parents) + 1\n",
    "    \n",
    "    def get_edges(self, node_name, node_id):\n",
    "        edges = np.zeros((len(node_name), len(node_name)))\n",
    "        for i,node in enumerate(node_name):\n",
    "            if node != self.root:\n",
    "                edges[i,node_id[self.parents[node]]] = 1\n",
    "        return torch.Tensor(edges).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_changes(edges1, edges_list, node_name):\n",
    "    new_locs = {}\n",
    "    for edges2 in edges_list:\n",
    "        loc1 = edges1.argmax(-1).reshape(-1)\n",
    "        loc2 = edges2.argmax(-1).reshape(-1)\n",
    "        for i,(l1, l2) in enumerate(zip(loc1, loc2)):\n",
    "            if l1 != 0 and l1 != l2:\n",
    "                if node_name[i] not in new_locs:\n",
    "                    new_locs[node_name[i]] = node_name[l2]\n",
    "                    print(f'Object {node_name[i]} moved from {node_name[l1]} to {node_name[l2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def d(dmin, dmax):\n",
    "    return (random.random()*(dmax-dmin))+dmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_graph = Graph('kitchen')\n",
    "initial_graph.add(node='shelf', parent='kitchen', category='Furniture')\n",
    "initial_graph.add(node='drawer', parent='kitchen', category='Furniture')\n",
    "initial_graph.add(node='sink', parent='kitchen', category='Furniture')\n",
    "initial_graph.add(node='counter', parent='kitchen', category='Furniture')\n",
    "initial_graph.add(node='fridge', parent='kitchen', category='Furniture')\n",
    "initial_graph.add(node='table', parent='kitchen', category='Furniture')\n",
    "\n",
    "initial_graph.add(node='cereal', parent='shelf')\n",
    "initial_graph.add(node='bowl', parent='drawer')\n",
    "initial_graph.add(node='pills', parent='drawer')\n",
    "initial_graph.add(node='banana', parent='counter')\n",
    "initial_graph.add(node='glass', parent='counter')\n",
    "initial_graph.add(node='milk', parent='fridge')\n",
    "# print(initial_graph.parents)\n",
    "initial_graph.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_graph.dump('demo_graph.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_routine(graph, initial_time, steps):\n",
    "    time = initial_time\n",
    "    graph_list = [deepcopy(graph.to_dict())]\n",
    "    time_list = [initial_time]\n",
    "    for ((obj, loc), (dmin, dmax)) in steps:\n",
    "        duration = d(dmin, dmax)\n",
    "        graph.move(obj, loc)\n",
    "        time += duration\n",
    "        graph_list.append(deepcopy(graph.to_dict()))\n",
    "        time_list.append(deepcopy(time))\n",
    "    obj_in_use = [[] for _ in range(len(graph_list))]\n",
    "    return {\"graphs\":graph_list, \"times\": time_list, \"objects_in_use\":obj_in_use}\n",
    "\n",
    "\n",
    "breakfast_routine_steps = [\n",
    "        (('cereal', 'table'), (60,90)),\n",
    "        (('milk', 'table'), (3,5)),\n",
    "        (('bowl', 'table'), (3,5)),\n",
    "        (('glass', 'table'), (3,5)),\n",
    "        (('milk', 'fridge'), (10,15)),\n",
    "        (('bowl', 'sink'), (10,15)),\n",
    "        (('glass', 'sink'), (3,5)),\n",
    "        (('cereal', 'shelf'), (3,5))\n",
    "    ]\n",
    "    \n",
    "medication_steps = [\n",
    "        (('pills', 'table'), (60,90)),\n",
    "        (('glass', 'table'), (3,5)),\n",
    "        (('glass', 'sink'), (10,15)),\n",
    "        (('pills', 'drawer'), (3,5))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_breakfast_prob = 1\n",
    "directory = 'data/demo_routines'\n",
    "if os.path.exists(directory):\n",
    "    shutil.rmtree(directory)\n",
    "\n",
    "os.makedirs(directory)\n",
    "\n",
    "inf = {\"dt\": 5, \n",
    "\"num_train_routines\": 50, \n",
    "\"num_test_routines\": 10, \n",
    "\"weekend_days\": [], \n",
    "\"start_time\": 0, \n",
    "\"end_time\": 500, \n",
    "\"interleaving\": False, \n",
    "\"only_used_objects\": True, \n",
    "\"num_nodes\": initial_graph.num_nodes(), \n",
    "\"search_object_ids\": [], \n",
    "\"search_object_names\": []}\n",
    "\n",
    "with open(os.path.join(directory,\"info.json\"), 'w') as f:\n",
    "    json.dump(inf,f)\n",
    "with open(os.path.join(directory,\"classes.json\"), 'w') as f:\n",
    "    classes_dict = {'nodes':initial_graph.to_dict()['nodes'], 'edges':['INSIDE','ON']}\n",
    "    json.dump(classes_dict,f)\n",
    "\n",
    "os.makedirs(os.path.join(directory,'routines_train'))\n",
    "for i in range(inf[\"num_train_routines\"]):\n",
    "    print(initial_graph.parents)\n",
    "    routine = execute_routine(initial_graph, inf[\"start_time\"], breakfast_routine_steps+medication_steps)\n",
    "    \n",
    "    with open(os.path.join(directory,'routines_train',\"{:3d}.json\".format(i)), 'w') as f:\n",
    "        json.dump(routine, f)\n",
    "\n",
    "os.makedirs(os.path.join(directory,'routines_test'))\n",
    "for i in range(inf[\"num_test_routines\"]):\n",
    "    routine = execute_routine(initial_graph, inf[\"start_time\"], breakfast_routine_steps+medication_steps)\n",
    "    \n",
    "    with open(os.path.join(directory,'routines_test',\"{:3d}.json\".format(i)), 'w') as f:\n",
    "        json.dump(routine, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! [ -d data/demo_routines_simple/processed ] || ~/.conda/envs/pyml/bin/python3 ./readerFileBased.py --path=data/demo_routines_simple\n",
    "# ! ~/.conda/envs/pyml/bin/python3 ./run.py --path=data/demo_routines_simple --name=ours --tags=demo --train_days=50 --logs_dir=logs_demo_simple/50 --write_ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/demo_routines/processed/common_data.json') as f:\n",
    "    common_data = json.load(f)\n",
    "\n",
    "node_name = common_data['node_classes']\n",
    "node_id = {n:i for i,n in enumerate(node_name)}\n",
    "\n",
    "standard_nodes = torch.Tensor(np.eye(len(node_name))).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'logs/demo_routines/demo_routines/ours_5epochs'\n",
    "\n",
    "with open (os.path.join(log_dir,'config.json')) as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "time_encoding_func = TimeEncodingOptions()(cfg['TIME_ENCODING'])\n",
    "\n",
    "data=cfg['DATA_PARAM']\n",
    "checkpoint_file = glob.glob(log_dir+'/*.ckpt')[0]\n",
    "\n",
    "\n",
    "model = GraphTranslatorModule.load_from_checkpoint(checkpoint_file, \n",
    "                                                    num_nodes=data['n_nodes'],\n",
    "                                                    node_feature_len=data['n_len'],\n",
    "                                                    context_len=data['c_len'],\n",
    "                                                    edge_importance=cfg['EDGE_IMPORTANCE'],\n",
    "                                                    edge_dropout_prob = cfg['EDGE_DROPOUT_PROB'],\n",
    "                                                    tn_loss_weight=cfg['TN_LOSS_WEIGHT'],\n",
    "                                                    learned_time_periods=cfg['LEARNED_TIME_PERIODS'],\n",
    "                                                    hidden_layer_size=cfg['HIDDEN_LAYER_SIZE'])\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(log_dir,'weights.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph('kitchen')\n",
    "\n",
    "graph.add(node='shelf', parent='kitchen', category='Furniture')\n",
    "graph.add(node='drawer', parent='kitchen', category='Furniture')\n",
    "graph.add(node='sink', parent='kitchen', category='Furniture')\n",
    "graph.add(node='counter', parent='kitchen', category='Furniture')\n",
    "graph.add(node='fridge', parent='kitchen', category='Furniture')\n",
    "graph.add(node='table', parent='kitchen', category='Furniture')\n",
    "\n",
    "graph.add(node='cereal', parent='shelf')\n",
    "graph.add(node='bowl', parent='drawer')\n",
    "graph.add(node='pills', parent='drawer')\n",
    "graph.add(node='banana', parent='counter')\n",
    "graph.add(node='glass', parent='counter')\n",
    "graph.add(node='milk', parent='fridge')\n",
    "\n",
    "graph.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proactivity_window = 5\n",
    "\n",
    "prev_edges = graph.get_edges(node_name,node_id)\n",
    "prev_time = 60\n",
    "\n",
    "batch = {}\n",
    "\n",
    "batch['edges'] = prev_edges\n",
    "batch['nodes'] = standard_nodes\n",
    "batch['y_edges'] = prev_edges\n",
    "batch['y_nodes'] = standard_nodes\n",
    "batch['dynamic_edges_mask'] = torch.tensor(np.ones_like(prev_edges)-np.eye((prev_edges.size()[-1])))\n",
    "batch['dynamic_edges_mask'][:,:7,:] = 0\n",
    "batch['context'] = time_encoding_func(prev_time)\n",
    "\n",
    "edges_seq = []\n",
    "\n",
    "for _ in range(proactivity_window):\n",
    "    _, details = model.step(batch)\n",
    "    edg = (details['output_probs']['location']).to(torch.float32)\n",
    "    gt_tensor = details['gt']['location'][details['evaluate_node']]\n",
    "    output_tensor = details['output']['location'][details['evaluate_node']]\n",
    "    input_tensor = details['input']['location'][details['evaluate_node']]\n",
    "    prev_time += cfg['DATA_INFO']['dt']\n",
    "    edges_seq.append(edg)\n",
    "    batch['edges'] = edg\n",
    "    batch['context'] = time_encoding_func(prev_time)\n",
    "    \n",
    "print_changes(prev_edges, edges_seq, node_name)\n",
    "\n",
    "edg.argmax(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_edges(node_name,node_id).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_changes(graph.get_edges(node_name,node_id), edg, node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = RoutinesDataset(data_path=os.path.join(directory,'processed'), \n",
    "                        time_encoder=time_encoding_func, \n",
    "                        batch_size=cfg['BATCH_SIZE'],\n",
    "                        only_seen_edges = cfg['ONLY_SEEN_EDGES'],\n",
    "                        max_routines = (50, None))\n",
    "\n",
    "visualize_conditional_datapoint(model, data.get_single_example_test_loader(), data.node_classes, use_output_nodes=cfg['LEARN_NODES'])\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = data.get_single_example_test_loader()\n",
    "tl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.dataset[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from DemoRoutine import evaluate_model, generate_data, Graph, print_time, get_initial_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ! mv data/demo_routines data/demo_routines_old\n",
    "# generate_data()\n",
    "\n",
    "# # ! python3 ./readerFileBased.py --path=data/demo_routines\n",
    "# # ! python3 ./run.py --path=data/demo_routines --name=ours --tags=demo --logs_dir=logs --write_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06:20'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# graph = Graph('kitchen')\n",
    "\n",
    "# graph.add(node='shelf', parent='kitchen', category='Furniture')\n",
    "# graph.add(node='drawer', parent='kitchen', category='Furniture')\n",
    "# graph.add(node='sink', parent='kitchen', category='Furniture')\n",
    "# graph.add(node='counter', parent='kitchen', category='Furniture')\n",
    "# graph.add(node='fridge', parent='kitchen', category='Furniture')\n",
    "# graph.add(node='table', parent='kitchen', category='Furniture')\n",
    "\n",
    "# graph.add(node='cereal', parent='shelf')\n",
    "# graph.add(node='bowl', parent='drawer')\n",
    "# graph.add(node='pills', parent='drawer')\n",
    "# graph.add(node='waterbottle', parent='counter')\n",
    "# graph.add(node='glass', parent='counter')\n",
    "# graph.add(node='milk', parent='fridge')\n",
    "\n",
    "graph = get_initial_graph()\n",
    "\n",
    "time = 40\n",
    "\n",
    "print_time(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph.move('bowl', 'table')\n",
      "time += 20\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(graph, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.move('bowl', 'table')\n",
    "graph.move('milk', 'table')\n",
    "time += 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06:40'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_time(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graph.move('cereal', 'table')\n",
    "graph.move('bowl', 'table')\n",
    "graph.move('milk', 'table')\n",
    "time += 20\n",
    "\n",
    "graph.move('glass', 'table')\n",
    "time += 20\n",
    "\n",
    "graph.move('milk', 'fridge')\n",
    "graph.move('cereal', 'shelf')\n",
    "time += 20\n",
    "\n",
    "graph.move('bowl', 'sink')\n",
    "graph.move('glass', 'sink')\n",
    "time += 20\n",
    "\n",
    "graph.move('pills', 'table')\n",
    "time += 20\n",
    "\n",
    "time += 20\n",
    "\n",
    "graph.move('pills', 'drawer')\n",
    "time += 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f2dbfa5ef75a9144d7b0485e8c79d6707cb4300dbf38d3b3596c375ba449bc0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pyml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
