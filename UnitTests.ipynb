{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests to sanity check the network's capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GraphTranslatorModule import GraphTranslatorModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dictionary = {}\n",
    "node_dictionary['kitchen'] = {\"id\": 1, \"class_name\": \"kitchen\", \"category\": \"Rooms\", \"properties\": [], \"states\": [], \"prefab_name\": None, \"bounding_box\": None}\n",
    "node_dictionary['cabinet'] = {\"id\": 2, \"class_name\": \"cabinet\", \"category\": \"Furniture\", \"properties\": [], \"states\": [\"CLOSED\"], \"prefab_name\": None, \"bounding_box\": None}\n",
    "node_dictionary['table'] = {\"id\": 3, \"class_name\": \"table\", \"category\": \"Furniture\", \"properties\": [], \"states\": [\"CLOSED\"], \"prefab_name\": None, \"bounding_box\": None}\n",
    "node_dictionary['sink'] = {\"id\": 4, \"class_name\": \"sink\", \"category\": \"Furniture\", \"properties\": [], \"states\": [\"CLOSED\"], \"prefab_name\": None, \"bounding_box\": None}\n",
    "node_dictionary['cup'] = {\"id\": 5, \"class_name\": \"cup\", \"category\": \"placable_objects\", \"properties\": [], \"states\": [\"CLEAN\"], \"prefab_name\": None, \"bounding_box\": None}\n",
    "node_dictionary['cereal'] = {\"id\": 6, \"class_name\": \"cereal\", \"category\": \"placable_objects\", \"properties\": [], \"states\": [\"CLEAN\"], \"prefab_name\": None, \"bounding_box\": None}\n",
    "node_dictionary['toast'] = {\"id\": 7, \"class_name\": \"toast\", \"category\": \"placable_objects\", \"properties\": [], \"states\": [\"CLEAN\"], \"prefab_name\": None, \"bounding_box\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge(from_node, relation, to_node):\n",
    "    return {'from_id':node_dictionary[from_node]['id'], 'relation_type':relation, 'to_id':node_dictionary[to_node]['id']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 10\n",
    "\n",
    "def time_internal(mins, hrs, days=0, weeks=0):\n",
    "    return int(round(((((weeks*7+days)*24)+hrs)*60+mins)/dt))\n",
    "\n",
    "def time_external(in_t):\n",
    "    in_t = in_t*dt\n",
    "    mins = in_t % 60\n",
    "    in_t = in_t // 60\n",
    "    hrs = in_t % 24\n",
    "    in_t = in_t // 24\n",
    "    days = in_t % 7\n",
    "    in_t = in_t // 7\n",
    "    weeks = in_t\n",
    "    return(weeks, days, hrs, mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_a_result(idx = -1):\n",
    "    test_data = data._alldata[idx]\n",
    "    edges, nodes, context_curr, context_query, y = test_data\n",
    "    print(edges)\n",
    "    edges = edges.unsqueeze(0)  \n",
    "    nodes = nodes.unsqueeze(0)  \n",
    "    context_curr = context_curr.unsqueeze(0)  \n",
    "    context_query = context_query.unsqueeze(0)  \n",
    "    x_hat = model.forward(edges, nodes, context_curr, context_query).squeeze()\n",
    "    print(x_hat)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1. No noise repeating case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/unittests/case1'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "\n",
    "nodes = [node_dictionary[key] for key in ['kitchen','cabinet','table','sink','cup']]\n",
    "print('Nodes : ',nodes)\n",
    "\n",
    "with open(os.path.join(data_dir,'classes.json'),'w') as f:\n",
    "    json.dump({\"nodes\":nodes, \"edges\": [\"INSIDE\"]}, f)\n",
    "\n",
    "data = []\n",
    "\n",
    "fixed_edges = []\n",
    "fixed_edges.append(edge('cabinet','INSIDE','kitchen'))\n",
    "fixed_edges.append(edge('table','INSIDE','kitchen'))\n",
    "fixed_edges.append(edge('sink','INSIDE','kitchen'))\n",
    "\n",
    "edges_0 = []\n",
    "edges_0.append(edge('cup','INSIDE','cabinet'))\n",
    "\n",
    "edges_1 = []\n",
    "edges_1.append(edge('cup','INSIDE','table'))\n",
    "\n",
    "edges_2 = []\n",
    "edges_2.append(edge('cup','INSIDE','sink'))\n",
    "\n",
    "changing_edges = [edges_0, edges_1, edges_2, edges_0]\n",
    "\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0), time_internal(40,8,0,0), time_internal(0,9,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0), time_internal(40,8,0,0), time_internal(0,9,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0), time_internal(40,8,0,0), time_internal(0,9,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0), time_internal(40,8,0,0), time_internal(0,9,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0), time_internal(40,8,0,0), time_internal(0,9,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "\n",
    "with open(os.path.join(data_dir,'sample.json'),'w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import RoutinesDataset\n",
    "from encoders import time_external, time_external_normalized, time_sine_cosine\n",
    "from analyzers import *\n",
    "\n",
    "data = RoutinesDataset(data_path=os.path.join(data_dir,'sample.json'), classes_path=os.path.join(data_dir,'classes.json'), time_encoder=time_sine_cosine)\n",
    "\n",
    "logging_analyzers = [MeanLoss(), EdgeTypeLoss(data.get_edge_classes())]\n",
    "\n",
    "model = GraphTranslatorModule(num_nodes=data.n_nodes, \n",
    "                              node_feature_len=data.n_len, \n",
    "                              edge_feature_len=data.e_len, \n",
    "                              context_len=data.c_len, \n",
    "                              train_analyzer=MeanLoss(), \n",
    "                              logging_analyzers=logging_analyzers)\n",
    "\n",
    "\n",
    "wandb_logger = WandbLogger()\n",
    "trainer = Trainer(max_epochs=250, logger=wandb_logger, log_every_n_steps=1)\n",
    "trainer.fit(model, data.get_train_loader())\n",
    "trainer.test(model, data.get_test_loader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2. No noise repeating case with multiple edge types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/unittests/case2'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "\n",
    "nodes = [node_dictionary[key] for key in ['kitchen','cabinet','table','sink','cup']]\n",
    "\n",
    "with open(os.path.join(data_dir,'classes.json'),'w') as f:\n",
    "    json.dump({\"nodes\":nodes, \"edges\": [\"ON\",\"INSIDE\",\"CLOSE\"]}, f)\n",
    "\n",
    "data = []\n",
    "\n",
    "fixed_edges = []\n",
    "fixed_edges.append(edge('cabinet','INSIDE','kitchen'))\n",
    "fixed_edges.append(edge('table','INSIDE','kitchen'))\n",
    "fixed_edges.append(edge('sink','INSIDE','kitchen'))\n",
    "\n",
    "edges_0 = []\n",
    "edges_0.append(edge('cup','INSIDE','cabinet'))\n",
    "edges_0.append(edge('cup','CLOSE','cabinet'))\n",
    "edges_0.append(edge('cabinet','CLOSE','cup'))\n",
    "\n",
    "edges_1 = []\n",
    "edges_1.append(edge('cup','ON','table'))\n",
    "edges_1.append(edge('cup','CLOSE','table'))\n",
    "edges_1.append(edge('table','CLOSE','cup'))\n",
    "\n",
    "edges_2 = []\n",
    "edges_2.append(edge('cup','INSIDE','sink'))\n",
    "edges_2.append(edge('cup','CLOSE','sink'))\n",
    "edges_2.append(edge('sink','CLOSE','cup'))\n",
    "\n",
    "changing_edges = [edges_0, edges_1, edges_2, edges_0]\n",
    "\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0), time_internal(40,8,0,0), time_internal(0,9,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0), time_internal(40,8,0,0), time_internal(0,9,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0), time_internal(40,8,0,0), time_internal(0,9,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0), time_internal(40,8,0,0), time_internal(0,9,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0), time_internal(40,8,0,0), time_internal(0,9,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "\n",
    "with open(os.path.join(data_dir,'sample.json'),'w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import RoutinesDataset\n",
    "from analyzers import *\n",
    "\n",
    "data = RoutinesDataset(data_path=os.path.join(data_dir,'sample.json'), classes_path=os.path.join(data_dir,'classes.json'))\n",
    "\n",
    "logging_analyzers = [MeanLoss(), EdgeTypeLoss(data.get_edge_classes())]\n",
    "\n",
    "model = GraphTranslatorModule(num_nodes=data.n_nodes, \n",
    "                              node_feature_len=data.n_len, \n",
    "                              edge_feature_len=data.e_len, \n",
    "                              context_len=data.c_len, \n",
    "                              train_analyzer=MeanLoss(), \n",
    "                              logging_analyzers=logging_analyzers)\n",
    "\n",
    "\n",
    "wandb_logger = WandbLogger()\n",
    "trainer = Trainer(max_epochs=250, logger=wandb_logger, log_every_n_steps=1)\n",
    "trainer.fit(model, data.get_train_loader())\n",
    "trainer.test(model, data.get_test_loader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3. No noise repeating case with different times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/unittests/case3'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "\n",
    "nodes = [node_dictionary[key] for key in ['kitchen','cabinet','table','sink','cup']]\n",
    "print('Nodes : ',nodes)\n",
    "\n",
    "with open(os.path.join(data_dir,'classes.json'),'w') as f:\n",
    "    json.dump({\"nodes\":nodes, \"edges\": [\"INSIDE\"]}, f)\n",
    "\n",
    "data = []\n",
    "\n",
    "fixed_edges = []\n",
    "fixed_edges.append(edge('cabinet','INSIDE','kitchen'))\n",
    "fixed_edges.append(edge('table','INSIDE','kitchen'))\n",
    "fixed_edges.append(edge('sink','INSIDE','kitchen'))\n",
    "\n",
    "edges_0 = []\n",
    "edges_0.append(edge('cup','INSIDE','cabinet'))\n",
    "\n",
    "edges_1 = []\n",
    "edges_1.append(edge('cup','INSIDE','table'))\n",
    "\n",
    "edges_2 = []\n",
    "edges_2.append(edge('cup','INSIDE','sink'))\n",
    "\n",
    "changing_edges = [edges_0, edges_1, edges_2, edges_0]\n",
    "\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0), time_internal(40,8,0,0), time_internal(0,9,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "graph_times = [time_internal(0,7,0,0), time_internal(20,7,0,0), time_internal(40,7,0,0), time_internal(0,8,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "graph_times = [time_internal(10,7,0,0), time_internal(20,7,0,0), time_internal(40,7,0,0), time_internal(0,8,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "graph_times = [time_internal(30,8,0,0), time_internal(00,9,0,0), time_internal(10,9,0,0), time_internal(30,9,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "graph_times = [time_internal(10,8,0,0), time_internal(50,8,0,0), time_internal(10,9,0,0), time_internal(30,9,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges]})\n",
    "\n",
    "with open(os.path.join(data_dir,'sample.json'),'w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import RoutinesDataset\n",
    "from analyzers import *\n",
    "\n",
    "data = RoutinesDataset(data_path=os.path.join(data_dir,'sample.json'), classes_path=os.path.join(data_dir,'classes.json'))\n",
    "\n",
    "logging_analyzers = [MeanLoss(), EdgeTypeLoss(data.get_edge_classes())]\n",
    "\n",
    "model = GraphTranslatorModule(num_nodes=data.n_nodes, \n",
    "                              node_feature_len=data.n_len, \n",
    "                              edge_feature_len=data.e_len, \n",
    "                              context_len=data.c_len, \n",
    "                              train_analyzer=MeanLoss(), \n",
    "                              logging_analyzers=logging_analyzers)\n",
    "\n",
    "\n",
    "wandb_logger = WandbLogger()\n",
    "trainer = Trainer(max_epochs=250, logger=wandb_logger, log_every_n_steps=1)\n",
    "trainer.fit(model, data.get_train_loader())\n",
    "trainer.test(model, data.get_test_loader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 4. 50-50 repeating case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/unittests/case4'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "\n",
    "nodes = [node_dictionary[key] for key in ['kitchen','cabinet','table','cereal','toast']]\n",
    "print('Nodes : ',nodes)\n",
    "\n",
    "with open(os.path.join(data_dir,'classes.json'),'w') as f:\n",
    "    json.dump({\"nodes\":nodes, \"edges\": [\"ON\",\"INSIDE\",\"CLOSE\"]}, f)\n",
    "\n",
    "data = []\n",
    "\n",
    "fixed_edges = []\n",
    "fixed_edges.append(edge('cabinet','INSIDE','kitchen'))\n",
    "fixed_edges.append(edge('table','INSIDE','kitchen'))\n",
    "fixed_edges.append(edge('sink','INSIDE','kitchen'))\n",
    "\n",
    "edges_0 = []\n",
    "edges_0.append(edge('cereal','INSIDE','cabinet'))\n",
    "edges_0.append(edge('cereal','CLOSE','cabinet'))\n",
    "edges_0.append(edge('toast','INSIDE','cabinet'))\n",
    "edges_0.append(edge('toast','CLOSE','cabinet'))\n",
    "\n",
    "edges_1a = []\n",
    "edges_1a.append(edge('toast','INSIDE','cabinet'))\n",
    "edges_1a.append(edge('toast','CLOSE','cabinet'))\n",
    "edges_1a.append(edge('cereal','ON','table'))\n",
    "edges_1a.append(edge('cereal','CLOSE','table'))\n",
    "\n",
    "edges_1b = []\n",
    "edges_1b.append(edge('cereal','INSIDE','cabinet'))\n",
    "edges_1b.append(edge('cereal','CLOSE','cabinet'))\n",
    "edges_1b.append(edge('toast','ON','table'))\n",
    "edges_1b.append(edge('toast','CLOSE','table'))\n",
    "\n",
    "\n",
    "changing_edges_a = [edges_0, edges_1a]\n",
    "changing_edges_b = [edges_0, edges_1b]\n",
    "\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges_a]})\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges_b]})\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges_a]})\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges_b]})\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges_a]})\n",
    "graph_times = [time_internal(0,8,0,0), time_internal(20,8,0,0)]\n",
    "data.append({\"times\":graph_times, \"graphs\":[{\"nodes\":nodes, \"edges\":edges+fixed_edges} for edges in changing_edges_b]})\n",
    "\n",
    "with open(os.path.join(data_dir,'sample.json'),'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import RoutinesDataset\n",
    "from analyzers import *\n",
    "\n",
    "data = RoutinesDataset(data_path=os.path.join(data_dir,'sample.json'), classes_path=os.path.join(data_dir,'classes.json'))\n",
    "\n",
    "logging_analyzers = [MeanLoss(), EdgeTypeLoss(data.get_edge_classes()), SpecificEdgeLoss(3,1, data.get_edge_classes(), 'cereal to cabinet'), SpecificEdgeLoss(3,2, data.get_edge_classes(), 'cereal to table'), SpecificEdgeLoss(4,1, data.get_edge_classes(), 'toast to cabinet'), SpecificEdgeLoss(4,2, data.get_edge_classes(), 'toast to table')]\n",
    "\n",
    "model = GraphTranslatorModule(num_nodes=data.n_nodes, \n",
    "                              node_feature_len=data.n_len, \n",
    "                              edge_feature_len=data.e_len, \n",
    "                              context_len=data.c_len, \n",
    "                              train_analyzer=MeanLoss(), \n",
    "                              logging_analyzers=logging_analyzers)\n",
    "\n",
    "\n",
    "wandb_logger = WandbLogger()\n",
    "trainer = Trainer(max_epochs=500, logger=wandb_logger, log_every_n_steps=1)\n",
    "trainer.fit(model, data.get_train_loader())\n",
    "trainer.test(model, data.get_test_loader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_a_result(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2494099ad36345242b6da11fc60f3e7f3d87cf26ba237a82612e243f5abafed"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
